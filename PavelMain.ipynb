{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OiBsyWYzBbxA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aeaacf1-b34c-4c52-d9ec-9e0e7834215f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting visdom\n",
            "  Downloading visdom-0.2.4.tar.gz (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.10/dist-packages (from visdom) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from visdom) (1.11.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from visdom) (2.31.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from visdom) (6.3.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from visdom) (1.16.0)\n",
            "Collecting jsonpatch (from visdom)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from visdom) (1.7.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from visdom) (3.2.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from visdom) (9.4.0)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch->visdom)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->visdom) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->visdom) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->visdom) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->visdom) (2023.11.17)\n",
            "Building wheels for collected packages: visdom\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.2.4-py3-none-any.whl size=1408194 sha256=1448350efd792a0bb4e14974c0d3f5d440063b1f313c1f8ff838dbc9e8a041c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/29/49/5bed207bac4578e4d2c0c5fc0226bfd33a7e2953ea56356855\n",
            "Successfully built visdom\n",
            "Installing collected packages: jsonpointer, jsonpatch, visdom\n",
            "Successfully installed jsonpatch-1.33 jsonpointer-2.4 visdom-0.2.4\n",
            "Collecting open3d\n",
            "  Downloading open3d-0.18.0-cp310-cp310-manylinux_2_27_x86_64.whl (399.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.7/399.7 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.23.5)\n",
            "Collecting dash>=2.6.0 (from open3d)\n",
            "  Downloading dash-2.14.2-py3-none-any.whl (10.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=2.2.3 in /usr/local/lib/python3.10/dist-packages (from open3d) (3.0.1)\n",
            "Requirement already satisfied: nbformat>=5.7.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (5.9.2)\n",
            "Collecting configargparse (from open3d)\n",
            "  Downloading ConfigArgParse-1.7-py3-none-any.whl (25 kB)\n",
            "Collecting ipywidgets>=8.0.4 (from open3d)\n",
            "  Downloading ipywidgets-8.1.1-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting addict (from open3d)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: pillow>=9.3.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (9.4.0)\n",
            "Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.10/dist-packages (from open3d) (3.7.1)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.5.3)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from open3d) (6.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from open3d) (4.66.1)\n",
            "Collecting pyquaternion (from open3d)\n",
            "  Downloading pyquaternion-0.9.9-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: Flask<3.1,>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.2.5)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (5.15.0)\n",
            "Collecting dash-html-components==2.0.0 (from dash>=2.6.0->open3d)\n",
            "  Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
            "Collecting dash-core-components==2.0.0 (from dash>=2.6.0->open3d)\n",
            "  Downloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
            "Collecting dash-table==5.0.0 (from dash>=2.6.0->open3d)\n",
            "  Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (4.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.31.0)\n",
            "Collecting retrying (from dash>=2.6.0->open3d)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Collecting ansi2html (from dash>=2.6.0->open3d)\n",
            "  Downloading ansi2html-1.9.1-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (67.7.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (7.0.1)\n",
            "Collecting comm>=0.1.3 (from ipywidgets>=8.0.4->open3d)\n",
            "  Downloading comm-0.2.1-py3-none-any.whl (7.2 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.9 (from ipywidgets>=8.0.4->open3d)\n",
            "  Downloading widgetsnbextension-4.0.9-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jupyterlab-widgets~=3.0.9 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (3.0.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (2.8.2)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (4.19.2)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (5.7.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->open3d) (2023.3.post1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=2.2.3->open3d) (2.1.4)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (8.1.7)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.32.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.17.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (8.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3->open3d) (1.16.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->dash>=2.6.0->open3d) (3.17.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->nbformat>=5.7.0->open3d) (4.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (2023.11.17)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.13)\n",
            "Installing collected packages: dash-table, dash-html-components, dash-core-components, addict, widgetsnbextension, retrying, pyquaternion, jedi, configargparse, comm, ansi2html, ipywidgets, dash, open3d\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.6\n",
            "    Uninstalling widgetsnbextension-3.6.6:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.6\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "Successfully installed addict-2.4.0 ansi2html-1.9.1 comm-0.2.1 configargparse-1.7 dash-2.14.2 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 ipywidgets-8.1.1 jedi-0.19.1 open3d-0.18.0 pyquaternion-0.9.9 retrying-1.3.4 widgetsnbextension-4.0.9\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.11.1.1\n",
            "/content/repo_folder\n",
            "Cloning into 'MSN-Point-Cloud-Completion'...\n",
            "remote: Enumerating objects: 175, done.\u001b[K\n",
            "remote: Counting objects: 100% (111/111), done.\u001b[K\n",
            "remote: Compressing objects: 100% (79/79), done.\u001b[K\n",
            "remote: Total 175 (delta 60), reused 73 (delta 31), pack-reused 64\u001b[K\n",
            "Receiving objects: 100% (175/175), 5.78 MiB | 5.68 MiB/s, done.\n",
            "Resolving deltas: 100% (86/86), done.\n",
            "/content/repo_folder/MSN-Point-Cloud-Completion\n",
            "Branch 'Pavel' set up to track remote branch 'Pavel' from 'origin'.\n",
            "Switched to a new branch 'Pavel'\n",
            "Cloning into 'SoftPool'...\n",
            "remote: Enumerating objects: 170, done.\u001b[K\n",
            "remote: Counting objects: 100% (107/107), done.\u001b[K\n",
            "remote: Compressing objects: 100% (79/79), done.\u001b[K\n",
            "remote: Total 170 (delta 49), reused 73 (delta 24), pack-reused 63\u001b[K\n",
            "Receiving objects: 100% (170/170), 113.43 MiB | 14.04 MiB/s, done.\n",
            "Resolving deltas: 100% (59/59), done.\n"
          ]
        }
      ],
      "source": [
        "first = True\n",
        "get_base_data = False\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "drivef = \"/content/drive/MyDrive/\"\n",
        "if first:\n",
        "  !pip install visdom\n",
        "  !pip install open3d\n",
        "  !pip install ninja\n",
        "  if True:\n",
        "    !mkdir /content/repo_folder\n",
        "    !rm -rf /content/MSN-Point-Cloud-Completion\n",
        "    %cd /content/repo_folder\n",
        "    !git clone https://github.com/iwillnotkillyou/MSN-Point-Cloud-Completion.git\n",
        "    %cd ./MSN-Point-Cloud-Completion\n",
        "    !git checkout Pavel\n",
        "  !git clone https://github.com/alexandrosstergiou/SoftPool.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "import torch\n",
        "if False:\n",
        "  olf = \"SoftPool/pytorch/CUDA\"\n",
        "  newf = \"softpool_cuda\"\n",
        "  tempn = \"tempnamed\"\n",
        "  os.rename(newf, tempn)\n",
        "  !cp -r $olf ./\n",
        "  os.rename(\"CUDA\", newf)\n",
        "  n = \"soft_pool_cuda_module.py\"\n",
        "  copiedfn = str(Path(tempn) / n)\n",
        "  destfn = str(Path(newf) / n)\n",
        "  !cp $copiedfn $destfn\n",
        "  !rm -r \"CUDA\"\n",
        "  !rm -r $tempn\n",
        "  from softpool_cuda.soft_pool_cuda_module import soft_pool3d, SoftPool3d\n",
        "  r = SoftPool3d()(torch.ones(100,3,100,100,100))\n",
        "  print(r.shape)"
      ],
      "metadata": {
        "id": "NqRsI07Rr2QQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "dataf = \"/content/repo_folder/MSN-Point-Cloud-Completion/data\"\n",
        "if first:\n",
        "  if get_base_data:\n",
        "    !unzip -o /content/drive/MyDrive/val.zip -d $dataf\n",
        "    !unzip -o /content/drive/MyDrive/complete.zip -d $dataf\n",
        "    listp = f'{dataf}/train.list'\n",
        "    valp = f'{dataf}/val.list'\n",
        "    listop = f'{drivef}/train.list'\n",
        "    valop = f'{drivef}/val.list'\n",
        "    !cp $listop $listp\n",
        "    !cp $valop $valp\n",
        "  %cd /content/repo_folder/MSN-Point-Cloud-Completion\n",
        "  !mkdir \"/content/repo_folder/MSN-Point-Cloud-Completion/trained_model\"\n",
        "  !cp \"/content/drive/MyDrive/network.pth\" \"/content/repo_folder/MSN-Point-Cloud-Completion/trained_model/network.pth\""
      ],
      "metadata": {
        "id": "xt0Q5uPzKU8x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bd81b7f-0a63-4237-ed90-0922bf314219"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/repo_folder/MSN-Point-Cloud-Completion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if False:\n",
        "  dataf = \"/content/repo_folder/MSN-Point-Cloud-Completion/data\"\n",
        "  print('Downloading ...')\n",
        "  !wget http://kaldir.vc.in.tum.de/cdiller/ShapeNetPointClouds.zip -P $dataf\n",
        "  print('Extracting ...')\n",
        "  fp = dataf + '/ShapeNetPointClouds.zip'\n",
        "  !unzip -o -q $fp -d $dataf\n",
        "  !rm $fp\n",
        "  print('Done.')"
      ],
      "metadata": {
        "id": "_jw7HyJUdLVZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if False:\n",
        "  dataf = \"/content/repo_folder/MSN-Point-Cloud-Completion/data\"\n",
        "  fp = dataf + '/dataset.zip'\n",
        "  !wget https://cloud.tsinghua.edu.cn/f/06a3c383dc474179b97d/?dl=1 -O $fp\n",
        "  !unzip -o -q $fp -d $dataf"
      ],
      "metadata": {
        "id": "BJmPpqyxipAC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if False:\n",
        "  !python val.py"
      ],
      "metadata": {
        "id": "Gxiu0V4GWOsz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/repo_folder/MSN-Point-Cloud-Completion\n",
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import expansion_penalty.expansion_penalty_module as expansion\n",
        "import MDS.MDS_module as MDS_module\n",
        "from model import *\n",
        "\n",
        "class LocallyConnected1d():\n",
        "    def __init__(self, in_channels,out_channels,output_size, bias = False, kernel_size = 1, stride = 1):\n",
        "        super().__init__()\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.weight = nn.Parameter(\n",
        "            torch.randn(output_size, out_channels, in_channels * kernel_size)\n",
        "        )\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(\n",
        "                torch.randn(out_channels, output_size)\n",
        "            )\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "    def forward(self,x):\n",
        "        x = x.unfold(1, self.kernel_size, self.stride)\n",
        "        out = torch.matmul(x.unsqueeze(2), self.weight).squeeze()\n",
        "        if self.bias is not None:\n",
        "            out += self.bias\n",
        "        return out\n",
        "\n",
        "class SimpleLocallyConnected1d():\n",
        "    def __init__(self, in_channels,out_channels,output_size, bias = False):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(\n",
        "            torch.randn(output_size, out_channels, in_channels)\n",
        "        )\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(\n",
        "                torch.randn(output_size, out_channels)\n",
        "            )\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "    def forward(self,x):\n",
        "        out = torch.matmul(x.unsqueeze(2),self.weight).squeeze()\n",
        "        if self.bias is not None:\n",
        "            out += self.bias\n",
        "        return out\n",
        "\n",
        "class ResSizes(nn.Module):\n",
        "    def __init__(self, sizesup, sizesdown):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        lsup = []\n",
        "        for i in range(len(sizesup)-1):\n",
        "            lsup.append(BatchNormConv1D(sizesup[i],sizesup[i+1]))\n",
        "        lsdown = []\n",
        "        for i in range(len(sizesdown)-1):\n",
        "            lsdown.append(BatchNormConv1D(sizesdown[i] + (0 if i != 0 else sizesup[0]),sizesdown[i+1]))\n",
        "        self.sizesdown = sizesdown\n",
        "        self.sizesup = sizesup\n",
        "        self.convsup = torch.nn.Sequential(*lsup)\n",
        "        self.convsdown = torch.nn.Sequential(*lsdown)\n",
        "        self.conv1 = BatchNormConv1D(4, sizesup[0])\n",
        "        self.convlast = torch.nn.Conv1d(sizesdown[-1], 3, 1)\n",
        "        self.bnlast = torch.nn.BatchNorm1d(3)\n",
        "        self.th = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize = x.size()[0]\n",
        "        npoints = x.size()[2]\n",
        "        x = self.conv1(x)\n",
        "        pointfeat = x\n",
        "        x = self.convsup(x)\n",
        "        s = x.size()[1]\n",
        "        softmaxweights = F.softmax(x,2)\n",
        "        x = (softmaxweights*x).sum(2)\n",
        "        x = x.view(batchsize, -1, 1)\n",
        "        x = x.broadcast_to(x.shape[0], x.shape[1], npoints)\n",
        "        x = torch.cat([x, pointfeat], 1)\n",
        "        x = self.convsdown(x)\n",
        "        x = self.th(self.bnlast(self.convlast(x)))\n",
        "        return x\n",
        "\n",
        "class BatchNormLocalConv1D(nn.Module):\n",
        "    def __init__(self, in_channels,out_channels,output_size,kernel_size = 1, stride = 1):\n",
        "        super().__init__()\n",
        "        self.conv = LocallyConnected1d(in_channels,out_channels,output_size,False,kernel_size,stride)\n",
        "        self.bn = torch.nn.BatchNorm1d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.relu(self.bn(self.conv(x)))\n",
        "\n",
        "class BatchNormConv1D(nn.Module):\n",
        "    def __init__(self, in_channels,out_channels,kernel_size = 1, stride = 1):\n",
        "        super(BatchNormConv1D, self).__init__()\n",
        "        self.conv = nn.Conv1d(in_channels,out_channels,kernel_size,stride)\n",
        "        self.bn = torch.nn.BatchNorm1d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.relu(self.bn(self.conv(x)))\n",
        "\n",
        "class BatchNormConv1DTransformer(nn.Module):\n",
        "    def __init__(self, in_channels,out_channels,kernel_size = 1, stride = 1):\n",
        "        super(BatchNormConv1DTransformer, self).__init__()\n",
        "        self.conv = nn.Conv1d(in_channels,out_channels,kernel_size,stride)\n",
        "        self.bn = torch.nn.BatchNorm1d(out_channels)\n",
        "\n",
        "    def forward(self, _, __, x):\n",
        "        return F.relu(self.bn(self.conv(x)))\n",
        "\n",
        "def make(sizes,f,additional_args = None):\n",
        "    return [f(*([sizes[i],sizes[i+1]]+ [] if additional_args is None or additional_args[i] is None else additional_args[i])) for i in range(len(sizes)-1)]\n",
        "\n",
        "class GlobalTransform(nn.Module):\n",
        "    def __init__(self, bottleneck_size, sizes, latents):\n",
        "        super().__init__()\n",
        "        self.bottleneck_size = bottleneck_size\n",
        "        self.latents = latents\n",
        "        sizes = (3,) + tuple(sizes) + (self.latents*self.latents,)\n",
        "        self.convs = nn.Sequential(*make(sizes, lambda x,y : nn.Sequential(BatchNormConv1D(x,y))))\n",
        "        self.register_buffer('identity', torch.diag(torch.ones(self.latents)))\n",
        "\n",
        "\n",
        "    def forward(self, partial, x):\n",
        "        bs = x.shape[0]\n",
        "        x = x.view(bs,-1,self.latents).contiguous()\n",
        "        outs = []\n",
        "        transform_pre = self.convs(partial)\n",
        "        softmaxweights = F.softmax(transform_pre,2)\n",
        "        transform = (softmaxweights*transform_pre).sum(2).view(-1, self.latents, self.latents)\n",
        "        identity = torch.broadcast_to(self.identity.unsqueeze(0),(bs, self.identity.shape[0], self.identity.shape[1]))\n",
        "        transform = transform + identity\n",
        "        for i in range(x.shape[1]):\n",
        "          outs.append(torch.matmul(transform, x[:,i,:].unsqueeze(2)).squeeze())\n",
        "        return torch.cat(outs,1)\n",
        "\n",
        "class GlobalTransformIndentity(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "    def forward(self, partial, x):\n",
        "        return x\n",
        "\n",
        "def f(partial,x,expansion,num_points,n_primitives,residual,decoder):\n",
        "  outs = []\n",
        "  for i in range(0, n_primitives):\n",
        "    rand_grid = Variable(torch.cuda.FloatTensor(x.size(0), 2, num_points // n_primitives))\n",
        "    rand_grid.data.uniform_(0, 1)\n",
        "    y = x.unsqueeze(2).expand(x.size(0), x.size(1), rand_grid.size(2)).contiguous()\n",
        "    y = torch.cat((rand_grid, y), 1).contiguous()\n",
        "    outs.append(decoder[i](y))\n",
        "\n",
        "\n",
        "  outs = torch.cat(outs, 2)\n",
        "  out1 = outs.transpose(1, 2).contiguous()\n",
        "  dist, _, mean_mst_dis = expansion(out1, num_points // n_primitives, 1.5)\n",
        "  loss_mst = torch.mean(dist)\n",
        "\n",
        "  id0 = torch.zeros(outs.shape[0], 1, outs.shape[2], device=torch.device('cuda')).contiguous()\n",
        "  outs = torch.cat((outs, id0), 1)\n",
        "  id1 = torch.ones(partial.shape[0], 1, partial.shape[2], device=torch.device('cuda')).contiguous()\n",
        "  partial = torch.cat((partial, id1), 1)\n",
        "  xx = torch.cat((outs, partial), 2)\n",
        "\n",
        "  resampled_idx = MDS_module.minimum_density_sample(xx[:, 0:3, :].transpose(1, 2).contiguous(), out1.shape[1],mean_mst_dis)\n",
        "  xx = MDS_module.gather_operation(xx, resampled_idx)\n",
        "  delta = residual(xx)\n",
        "  xx = xx[:, 0:3, :]\n",
        "  out2 = (xx + delta).transpose(2, 1).contiguous()\n",
        "  return out1, out2, loss_mst\n",
        "\n",
        "\n",
        "\n",
        "class TransformMSN(nn.Module):\n",
        "    def __init__(self, residual, additional_encoder,\n",
        "                 num_points=8192, n_primitives=16):\n",
        "        super().__init__()\n",
        "        self.num_points = num_points\n",
        "        self.bottleneck_size = 1024\n",
        "        self.n_primitives = n_primitives\n",
        "        self.encoder = nn.Sequential(\n",
        "            PointNetfeat(num_points),\n",
        "            nn.Linear(1024, self.bottleneck_size),\n",
        "            nn.BatchNorm1d(self.bottleneck_size),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.decoder = nn.ModuleList(\n",
        "            [PointGenCon(bottleneck_size=2 + self.bottleneck_size) for i in range(0, self.n_primitives)])\n",
        "        self.additional_encoder = additional_encoder(self.bottleneck_size)\n",
        "        self.res = residual()\n",
        "        self.expansion = expansion.expansionPenaltyModule()\n",
        "\n",
        "    def freeze(self):\n",
        "        for param in self.encoder.parameters():\n",
        "            param.requires_grad = False\n",
        "        for param in self.decoder.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.res.freeze()\n",
        "\n",
        "    def forward(self, x):\n",
        "        partial = x\n",
        "        x = self.encoder(x)\n",
        "        x = self.additional_encoder(partial,x)\n",
        "        return f(partial,x,self.expansion,self.num_points,self.n_primitives,self.res,self.decoder)\n",
        "\n",
        "class TransformMSN2(nn.Module):\n",
        "    def __init__(self, residual, additional_encoder,\n",
        "                 num_points=8192, n_primitives=16):\n",
        "        super().__init__()\n",
        "        self.num_points = num_points\n",
        "        self.bottleneck_size = 1024\n",
        "        self.n_primitives = n_primitives\n",
        "        self.encoder = nn.Sequential(\n",
        "            PointNetfeat(num_points),\n",
        "            nn.Linear(1024, self.bottleneck_size),\n",
        "            nn.BatchNorm1d(self.bottleneck_size),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.decoder = nn.ModuleList(\n",
        "            [PointGenCon(bottleneck_size=2 + self.bottleneck_size) for i in range(0, self.n_primitives)])\n",
        "        print(self.decoder[0].conv3.out_channels)\n",
        "        self.additional_encoder = additional_encoder(self.bottleneck_size)\n",
        "        self.residual = residual()\n",
        "        self.expansion = expansion.expansionPenaltyModule()\n",
        "\n",
        "    def freeze(self):\n",
        "        for param in self.encoder.parameters():\n",
        "            param.requires_grad = False\n",
        "        for param in self.decoder.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        partial = x\n",
        "        x = self.encoder(x)\n",
        "        x = x + self.additional_encoder(partial)\n",
        "        return f(partial,x,self.expansion,self.num_points,self.n_primitives,self.residual,self.decoder)"
      ],
      "metadata": {
        "id": "ZL4O2v8jgjKB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10b78548-14b1-4c0e-96c8-089e980ed7cf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/repo_folder/MSN-Point-Cloud-Completion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import random\n",
        "#from utils import *\n",
        "\n",
        "def resample_pcd(pcd, n):\n",
        "    \"\"\"Drop or duplicate points so that pcd has exactly n points\"\"\"\n",
        "    idx = np.random.permutation(pcd.shape[0])\n",
        "    if idx.shape[0] < n:\n",
        "        idx = np.concatenate([idx, np.random.randint(pcd.shape[0], size = n - pcd.shape[0])])\n",
        "    return pcd[idx[:n]]\n",
        "\n",
        "class ShapeNet(data.Dataset):\n",
        "    def __init__(self, train = True, npoints = 8192):\n",
        "        if train:\n",
        "            self.list_path = './data/train.list'\n",
        "        else:\n",
        "            self.list_path = './data/val.list'\n",
        "        self.npoints = npoints\n",
        "        self.train = train\n",
        "\n",
        "        with open(os.path.join(self.list_path)) as file:\n",
        "            self.model_list = [line.strip().replace('/', '_') for line in file]\n",
        "        random.shuffle(self.model_list)\n",
        "        self.len = len(self.model_list * 50)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        model_id = self.model_list[index // 50]\n",
        "        scan_id = index % 50\n",
        "        def read_pcd(filename):\n",
        "            pcd = o3d.io.read_point_cloud(filename)\n",
        "            return torch.from_numpy(np.array(pcd.points)).float()\n",
        "        if self.train:\n",
        "            partial = read_pcd(os.path.join(\"./data/train/\", model_id + '_%d_denoised.pcd' % scan_id))\n",
        "        else:\n",
        "            partial = read_pcd(os.path.join(\"./data/val/\", model_id + '_%d_denoised.pcd' % scan_id))\n",
        "        complete = read_pcd(os.path.join(\"./data/complete/\", '%s.pcd' % model_id))\n",
        "        return model_id, resample_pcd(partial, 5000), resample_pcd(complete, self.npoints)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "class EmbeddingsDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, folder, embedder_batch_size, transform=None):\n",
        "        self.folder = folder\n",
        "        self.files = os.listdir(folder)\n",
        "        self.transform = transform\n",
        "        self.embedder_batch_size = embedder_batch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files*self.embedder_batch_size)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        id, x, target = torch.load(f\"{self.folder}/{self.files[idx // self.embedder_batch_size]}\")\n",
        "        i = idx % self.embedder_batch_size\n",
        "        try:\n",
        "          r = id[i], (x[0][i], x[1][i]), target[i]\n",
        "        except:\n",
        "          print(x[0].shape, x[1].shape)\n",
        "        return r"
      ],
      "metadata": {
        "id": "T_cjuAk0pgrZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FullModel(nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.EMD = emd.emdModule()\n",
        "\n",
        "    def forward(self, inputs, gt, eps, iters):\n",
        "        output1, output2, expansion_penalty = self.model(inputs)\n",
        "        gt = gt[:, :, :3]\n",
        "        idx = np.random.randint(gt.shape[1], self.model.num_points)\n",
        "        gt = gt[:, idx, :]\n",
        "        print(gt.shape)\n",
        "        print(output2.shape)\n",
        "        dist, _ = self.EMD(output1, gt, eps, iters)\n",
        "        emd1 = torch.sqrt(dist).mean(1)\n",
        "\n",
        "        dist, _ = self.EMD(output2, gt, eps, iters)\n",
        "        emd2 = torch.sqrt(dist).mean(1)\n",
        "\n",
        "        return output1, output2, emd1, emd2, expansion_penalty\n",
        "\n",
        "class PointNetResSoftMax(nn.Module):\n",
        "    def __init__(self, sizes):\n",
        "        super().__init__()\n",
        "        sizes = (1088,) + tuple(sizes)\n",
        "        self.conv1 = torch.nn.Conv1d(4, 64, 1)\n",
        "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
        "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
        "        self.bn1 = torch.nn.BatchNorm1d(64)\n",
        "        self.bn2 = torch.nn.BatchNorm1d(128)\n",
        "        self.bn3 = torch.nn.BatchNorm1d(1024)\n",
        "        self.convs = nn.Sequential(*make(sizes, lambda x,y : BatchNormConv1D(x,y)))\n",
        "        self.lastconv = torch.nn.Conv1d(sizes[-1], 3, 1)\n",
        "        self.th = nn.Tanh()\n",
        "\n",
        "    def freeze(self):\n",
        "        for param in self.parameters():\n",
        "          param.requires_grad = False\n",
        "        for param in self.convs.parameters():\n",
        "          param.requires_grad = True\n",
        "        for param in self.lastconv.parameters():\n",
        "          param.requires_grad = True\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize = x.size()[0]\n",
        "        npoints = x.size()[2]\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        pointfeat = x\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.bn3(self.conv3(x))\n",
        "        softmaxweights = F.softmax(x,2)\n",
        "        x = (softmaxweights*x).sum(2)\n",
        "        x = x.view(-1, 1024)\n",
        "        x = x.view(-1, 1024, 1).repeat(1, 1, npoints)\n",
        "        x = torch.cat([x, pointfeat], 1)\n",
        "        x = self.convs(x)\n",
        "        x = self.th(self.lastconv(x))\n",
        "        return x\n",
        "\n",
        "def make_fuller_model(name, args, architect_args):\n",
        "  def gtFunc(x):\n",
        "    return GlobalTransform(x,architect_args.gt_layer_sizes,architect_args.latents) if architect_args.use_gt else GlobalTransformIndentity()\n",
        "  def residualFunc():\n",
        "    return PointNetResSoftMax(architect_args.res_layer_sizes )\n",
        "  model = TransformMSN(residual = residualFunc, additional_encoder = gtFunc)\n",
        "  network = FullModel(model)\n",
        "  #network = torch.nn.DataParallel(network)\n",
        "  #model.apply(weights_init) #initialization of the weight\n",
        "\n",
        "  if name != '':\n",
        "      previous_state_dict = torch.load(name)\n",
        "      network.load_state_dict(previous_state_dict,True,True)\n",
        "      print(\"Previous weight loaded \")\n",
        "  elif args.base_model != '':\n",
        "      previous_state_dict = torch.load(args.base_model)\n",
        "      model.load_state_dict(previous_state_dict,False,True)\n",
        "      print(\"Previous weight loaded \")\n",
        "  model.freeze()\n",
        "  return network\n",
        "! mkdir /content/saved\n",
        "! wget -nc -O /content/saved/network.pth https://www.dropbox.com/scl/fi/qx16y8hkfaq0b7nh1k4b2/network.pth?rlkey=w6yjdwy3zpbf25h2qtak6kkq5&dl=0"
      ],
      "metadata": {
        "id": "X5sDPQeoyriv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56ea0e9e-e8b5-4a25-999b-8f511d87c6d3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-31 14:07:15--  https://www.dropbox.com/scl/fi/qx16y8hkfaq0b7nh1k4b2/network.pth?rlkey=w6yjdwy3zpbf25h2qtak6kkq5\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.81.18, 2620:100:6031:18::a27d:5112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.81.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc7358ae52eb413bab999059e959.dl.dropboxusercontent.com/cd/0/inline/CMZ4VriKAAwecl7GjQd8KamIrdyCq5lWl-yEbcxvI_RdZ2pmSa_2Z0KSEUchrO0dBSDGr18Q5wmmwTc8NEW0zhdpFMhjv-fC7VJTQVhiK7QKYHugrAYG5Vl59gVwUUa6kZVaI_5K8eWHgjYCFx5iRx0j/file# [following]\n",
            "--2024-01-31 14:07:16--  https://uc7358ae52eb413bab999059e959.dl.dropboxusercontent.com/cd/0/inline/CMZ4VriKAAwecl7GjQd8KamIrdyCq5lWl-yEbcxvI_RdZ2pmSa_2Z0KSEUchrO0dBSDGr18Q5wmmwTc8NEW0zhdpFMhjv-fC7VJTQVhiK7QKYHugrAYG5Vl59gVwUUa6kZVaI_5K8eWHgjYCFx5iRx0j/file\n",
            "Resolving uc7358ae52eb413bab999059e959.dl.dropboxusercontent.com (uc7358ae52eb413bab999059e959.dl.dropboxusercontent.com)... 162.125.81.15, 2620:100:6031:15::a27d:510f\n",
            "Connecting to uc7358ae52eb413bab999059e959.dl.dropboxusercontent.com (uc7358ae52eb413bab999059e959.dl.dropboxusercontent.com)|162.125.81.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/CMa-rO3L2xiOPlNwPjmHwBnZqlUVliaB2owv9nCEMblaxfRX78Mq1KcZK5JeYBtT-kk9Mt3hkPs6xT7NVYY5BkL9FkjY8I49Wvjkdr-uJe6-cwtV0tDRHMvsbJwR994znD_LBQIw2bx6y01wcin82_bDFA4YWJV7_RIcVX6rHFsxLSvBe-o7-aw5AhcJXl2yTm6x0wirNBYHpf8qBcf7Vh7OaQ_4FRkpfATKIsEqjJ35OCdJ3dD-TF3NMf2BhwABnz_TMBidASH4zr-UbJrDZvZcmBf3_YFEYmgI6EvAABxYykei8Ow4LVB3ysznCRjyaz_5SnDyvW8JsfG3AxG9QIcW8eQYhGSkbE7VWb2vD4XpBq2W3RCmwdCz6Awj_mF4czY/file [following]\n",
            "--2024-01-31 14:07:17--  https://uc7358ae52eb413bab999059e959.dl.dropboxusercontent.com/cd/0/inline2/CMa-rO3L2xiOPlNwPjmHwBnZqlUVliaB2owv9nCEMblaxfRX78Mq1KcZK5JeYBtT-kk9Mt3hkPs6xT7NVYY5BkL9FkjY8I49Wvjkdr-uJe6-cwtV0tDRHMvsbJwR994znD_LBQIw2bx6y01wcin82_bDFA4YWJV7_RIcVX6rHFsxLSvBe-o7-aw5AhcJXl2yTm6x0wirNBYHpf8qBcf7Vh7OaQ_4FRkpfATKIsEqjJ35OCdJ3dD-TF3NMf2BhwABnz_TMBidASH4zr-UbJrDZvZcmBf3_YFEYmgI6EvAABxYykei8Ow4LVB3ysznCRjyaz_5SnDyvW8JsfG3AxG9QIcW8eQYhGSkbE7VWb2vD4XpBq2W3RCmwdCz6Awj_mF4czY/file\n",
            "Reusing existing connection to uc7358ae52eb413bab999059e959.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 125687816 (120M) [application/octet-stream]\n",
            "Saving to: ‘/content/saved/network.pth’\n",
            "\n",
            "/content/saved/netw 100%[===================>] 119.87M  15.3MB/s    in 7.9s    \n",
            "\n",
            "2024-01-31 14:07:26 (15.1 MB/s) - ‘/content/saved/network.pth’ saved [125687816/125687816]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/repo_folder/MSN-Point-Cloud-Completion\n",
        "#! git fetch origin\n",
        "#! git reset --hard origin/master\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import open3d as o3d\n",
        "import argparse\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import sys\n",
        "from model import *\n",
        "from utils import *\n",
        "import os\n",
        "import json\n",
        "import time, datetime\n",
        "from time import time\n",
        "from torch.utils.cpp_extension import load\n",
        "import emd.emd_module as emd\n",
        "from tqdm import tqdm\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "def trainFull(network, dir_name, val_only, args):\n",
        "  lrate = 0.001 #learning rate\n",
        "  optimizer = optim.Adam(model.parameters(), lr = lrate)\n",
        "  train_curve = []\n",
        "  val_curve = []\n",
        "  labels_generated_points = (torch.Tensor(range(1, (args.n_primitives+1)*(args.num_points//args.n_primitives)+1))\n",
        "  .view(args.num_points//args.n_primitives,(args.n_primitives+1)).transpose(0,1))\n",
        "  labels_generated_points = (labels_generated_points)%(args.n_primitives+1)\n",
        "  labels_generated_points = labels_generated_points.contiguous().view(-1)\n",
        "  print(\"Random Seed: \", args.manualSeed)\n",
        "  random.seed(args.manualSeed)\n",
        "  torch.manual_seed(args.manualSeed)\n",
        "  best_val_loss = 10\n",
        "  network.to(\"cuda\")\n",
        "  x = ShapeNet(train=False, npoints=args.num_points)\n",
        "  perc_train = (1 - args.perc_val_data)*args.perc_data\n",
        "  perc_val = args.perc_val_data*args.perc_data\n",
        "  dataset, dataset_val, _ = torch.utils.data.random_split(x,[perc_train,perc_val,1-(perc_train+perc_val)])\n",
        "  dataloader = torch.utils.data.DataLoader(dataset, batch_size=args.batchSize,\n",
        "                                            shuffle=True, num_workers = args.workers,drop_last=True)\n",
        "  dataloader_val = torch.utils.data.DataLoader(dataset_val, batch_size=args.batchSize,\n",
        "                                            shuffle=False, num_workers = args.workers, drop_last=True)\n",
        "\n",
        "  len_dataset = len(dataset)\n",
        "  len_val_dataset = len(dataset_val)\n",
        "  print(\"Train Set Size: \", len_dataset)\n",
        "  try:\n",
        "    for epoch in range(args.nepoch):\n",
        "        train_loss = np.zeros(len(dataloader))\n",
        "        val_loss = np.zeros(len(dataloader_val))\n",
        "        #TRAIN MODE\n",
        "        model.train()\n",
        "\n",
        "        # learning rate schedule\n",
        "        if epoch==20:\n",
        "            optimizer = optim.Adam(model.parameters(), lr = lrate/10.0)\n",
        "        if epoch==40:\n",
        "            optimizer = optim.Adam(model.parameters(), lr = lrate/100.0)\n",
        "\n",
        "        if not val_only:\n",
        "          for i, data in enumerate(dataloader, 0):\n",
        "              if args.epoch_iter_limit is not None and i > args.epoch_iter_limit:\n",
        "                break\n",
        "              optimizer.zero_grad()\n",
        "              id, input, gt = data\n",
        "              input = input.float().cuda().transpose(1,2)\n",
        "              gt = gt.float().cuda()\n",
        "\n",
        "              output1, output2, emd1, emd2, expansion_penalty  = network(input, gt.contiguous(), 0.005, 10)\n",
        "              emd1m = emd1.mean()\n",
        "              emd1mi = emd1m.item()\n",
        "              emd2m = emd2.mean()\n",
        "              emd2mi = emd2m.item()\n",
        "              exppm = expansion_penalty.mean()\n",
        "              exppmi = exppm.item()\n",
        "              loss_net = emd1m + emd2m+ exppm * 0.1\n",
        "              train_loss[i] = emd2mi\n",
        "              loss_net.backward()\n",
        "              optimizer.step()\n",
        "\n",
        "              print(args.env + ' train [%d: %d/%d]  emd1: %f emd2: %f expansion_penalty: %f'\n",
        "                    %(epoch, i, len_dataset/args.batchSize, emd1mi, emd2mi,\n",
        "                      exppmi))\n",
        "              if (i*args.batchSize) % 100 == 0:\n",
        "                if not os.path.exists(dir_name):\n",
        "                  os.makedirs(dir_name)\n",
        "                torch.save(model.state_dict(), '%s/network.pth' % (dir_name))\n",
        "              del(input)\n",
        "          train_curve.append(np.mean(train_loss))\n",
        "\n",
        "        # VALIDATION\n",
        "        if epoch % 2 == 0:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                for i, data in enumerate(dataloader_val):\n",
        "                    if args.epoch_iter_limit_val is not None and i > args.epoch_iter_limit_val:\n",
        "                      break\n",
        "                    id,input, gt = data\n",
        "                    input = input.float().cuda().transpose(1,2)\n",
        "                    gt = gt.float().cuda()\n",
        "                    output1, output2, emd1, emd2, expansion_penalty  = network(input, gt.contiguous(), 0.004, 100 if val_only else 20)\n",
        "                    emd1m = emd1.mean()\n",
        "                    emd1mi = emd1m.item()\n",
        "                    emd2m = emd2.mean()\n",
        "                    emd2mi = emd2m.item()\n",
        "                    val_loss[i] = emd2mi\n",
        "                    exppm = expansion_penalty.mean()\n",
        "                    exppmi = exppm.item()\n",
        "                    idx = random.randint(0, input.size()[0] - 1)\n",
        "                    print(args.env + ' val [%d: %d/%d]  emd1: %f emd2: %f expansion_penalty: %f'\n",
        "                          %(epoch, i, len_val_dataset/args.batchSize, emd1mi,\n",
        "                            emd2mi, exppmi))\n",
        "                    del(input)\n",
        "\n",
        "        if not os.path.exists(dir_name):\n",
        "            os.mkdir(dir_name)\n",
        "        logname = os.path.join(dir_name, 'log.txt')\n",
        "        val_curve.append(np.mean(val_loss))\n",
        "        log_table = {\n",
        "          \"train_loss\" : np.mean(train_loss),\n",
        "          \"val_loss\" : np.mean(val_loss),\n",
        "          \"epoch\" : epoch,\n",
        "          \"lr\" : lrate,\n",
        "          \"bestval\" : best_val_loss,\n",
        "\n",
        "        }\n",
        "        with open(logname, 'a') as f:\n",
        "            f.write('json_stats: ' + json.dumps(log_table) + '\\n')\n",
        "\n",
        "        print('saving net...')\n",
        "        torch.save(model.state_dict(), '%s/network.pth' % (dir_name))\n",
        "  except:\n",
        "    del(dataset)\n",
        "    del(dataloader)\n",
        "    del(dataset_val)\n",
        "    del(dataloader_val)\n",
        "    raise\n",
        "\n",
        "from copy import copy\n",
        "now = datetime.datetime.now()\n",
        "\n",
        "try:\n",
        "  del(embedder)\n",
        "except:\n",
        "  pass\n",
        "try:\n",
        "  del(model)\n",
        "except:\n",
        "  pass\n",
        "\n",
        "if False:\n",
        "  embedder = make_embedder(args) if should_embed else None\n",
        "  in_c = embedder.decoder[0].conv3.out_channels if should_embed else 256\n",
        "  print(in_c)\n",
        "  #args.model = \"/content/drive/MyDrive/saved/model.py\"\n",
        "  model = make_model(in_c, args)\n",
        "  cs = 0\n",
        "  for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "      cs += param.nelement()\n",
        "      print(name, cs)\n",
        "  train(embedder, model,save_path, args)"
      ],
      "metadata": {
        "id": "wf6IuCTvaODK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8f7973c8-62a7-4916-8564-bb02d3e05dc2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/repo_folder/MSN-Point-Cloud-Completion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if first:\n",
        "  ! pip install transforms3d\n",
        "  %cd /content/repo_folder\n",
        "  ! rm -r /content/repo_folder/https:\n",
        "  ! git clone https://github.com/lynetcha/completion3d.git\n",
        "  %cd /content/repo_folder/completion3d\n",
        "%cd /content/repo_folder/completion3d\n",
        "chamferdir = \"/content/repo_folder/completion3d/pytorch/utils/chamfer\"\n",
        "try:\n",
        "  print(chamfer)\n",
        "except:\n",
        "  chamfer = load(name=\"chamfer\", sources=[f\"{chamferdir}/chamfer_cuda.cpp\",f\"{chamferdir}/chamfer.cu\"])\n",
        "  print(chamfer)\n",
        "\n",
        "class chamferFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, xyz1, xyz2):\n",
        "        batchsize, n, _ = xyz1.size()\n",
        "        _, m, _ = xyz2.size()\n",
        "\n",
        "        dist1 = torch.zeros(batchsize, n)\n",
        "        dist2 = torch.zeros(batchsize, m)\n",
        "\n",
        "        idx1 = torch.zeros(batchsize, n).type(torch.IntTensor)\n",
        "        idx2 = torch.zeros(batchsize, m).type(torch.IntTensor)\n",
        "\n",
        "        dist1 = dist1.cuda()\n",
        "        dist2 = dist2.cuda()\n",
        "        idx1 = idx1.cuda()\n",
        "        idx2 = idx2.cuda()\n",
        "\n",
        "        chamfer.forward(xyz1, xyz2, dist1, dist2, idx1, idx2)\n",
        "        ctx.save_for_backward(xyz1, xyz2, idx1, idx2)\n",
        "        return dist1, dist2\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, graddist1, graddist2):\n",
        "        xyz1, xyz2, idx1, idx2 = ctx.saved_tensors\n",
        "        graddist1 = graddist1.contiguous()\n",
        "        graddist2 = graddist2.contiguous()\n",
        "\n",
        "        gradxyz1 = torch.zeros(xyz1.size())\n",
        "        gradxyz2 = torch.zeros(xyz2.size())\n",
        "\n",
        "        gradxyz1 = gradxyz1.cuda()\n",
        "        gradxyz2 = gradxyz2.cuda()\n",
        "        chamfer.backward(xyz1, xyz2, gradxyz1, gradxyz2, graddist1, graddist2, idx1, idx2)\n",
        "        return gradxyz1, gradxyz2\n",
        "\n",
        "class chamferDist(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(chamferDist, self).__init__()\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        return chamferFunction.apply(input1, input2)\n",
        "\n",
        "try:\n",
        "  import h5py\n",
        "except:\n",
        "  ! pip install h5py\n",
        "  import h5py\n",
        "\n",
        "import pytorch._init_paths\n",
        "sys.path.insert(1, '/content/repo_folder/MSN-Point-Cloud-Completion/')\n",
        "sys.path.insert(1, '/content/repo_folder/completion3d/shared')\n",
        "sys.path.insert(1, '/content/repo_folder/completion3d/shared/datasets')\n",
        "sys.path.insert(1, '/content/repo_folder/completion3d/pytorch')\n",
        "\n",
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "import json\n",
        "import logging\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import os\n",
        "from collections import defaultdict\n",
        "import h5py\n",
        "from multiprocessing import Queue\n",
        "from data_process import kill_data_processes\n",
        "from shapenet import ShapenetDataProcess\n",
        "import subprocess\n",
        "\n",
        "def data_setup(args, phase, num_workers, repeat):\n",
        "    if args.dataset == 'shapenet':\n",
        "        DataProcessClass = ShapenetDataProcess\n",
        "    # Initialize data processes\n",
        "    data_queue = Queue(4 * num_workers)\n",
        "    data_processes =[]\n",
        "    for i in range(num_workers):\n",
        "        data_processes.append(DataProcessClass(data_queue, args, phase, repeat=repeat))\n",
        "        data_processes[-1].start()\n",
        "    return data_queue, data_processes\n",
        "\n",
        "def test(split, args, its = 100):\n",
        "    \"\"\" Evaluated model on test set \"\"\"\n",
        "    print(\"Testing....\")\n",
        "    args.model.eval()\n",
        "\n",
        "    data_queue, data_processes = data_setup(args, split, num_workers=1, repeat=False)\n",
        "    losses = []\n",
        "    N = len(data_processes[0].data_paths)\n",
        "    Nb = int(N/args.batch_size)\n",
        "    if Nb*args.batch_size < N:\n",
        "        Nb += 1\n",
        "    # iterate over dataset in batches\n",
        "    Nb = min(Nb,its)\n",
        "    for bidx in tqdm(range(Nb),total=Nb, position=0, leave=True):\n",
        "      targets, clouds_data = data_queue.get()\n",
        "\n",
        "      loss, dist1, dist2, emd_cost, outputs = args.step(targets, clouds_data)\n",
        "\n",
        "      losses.append(loss)\n",
        "\n",
        "    kill_data_processes(data_queue, data_processes)\n",
        "    return np.mean(losses)"
      ],
      "metadata": {
        "id": "p6-_53WpVy_G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdb4e036-be4a-47e8-f559-8dd3496319b3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transforms3d\n",
            "  Downloading transforms3d-0.4.1-py3-none-any.whl (1.4 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.4 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/1.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m1.2/1.4 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: transforms3d\n",
            "Successfully installed transforms3d-0.4.1\n",
            "/content/repo_folder\n",
            "rm: cannot remove '/content/repo_folder/https:': No such file or directory\n",
            "Cloning into 'completion3d'...\n",
            "remote: Enumerating objects: 194, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 194 (delta 3), reused 0 (delta 0), pack-reused 181\u001b[K\n",
            "Receiving objects: 100% (194/194), 1.31 MiB | 27.98 MiB/s, done.\n",
            "Resolving deltas: 100% (83/83), done.\n",
            "/content/repo_folder/completion3d\n",
            "/content/repo_folder/completion3d\n",
            "<module 'chamfer' from '/root/.cache/torch_extensions/py310_cu121/chamfer/chamfer.so'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%cd /content/repo_folder/completion3d\n",
        "def test_on_completion3D(args, download):\n",
        "  dir = \"/content/repo_folder/completion3d/data\"\n",
        "  test_data_queue, test_data_processes = data_setup(args, 'test', args.nworkers,\n",
        "                                                        repeat=True)\n",
        "  return test('train',args,50)\n",
        "\n",
        "\n",
        "\n",
        "def make_base_model(args):\n",
        "  model = MSN()\n",
        "  network = FullModel(model)\n",
        "  if args.base_model != '':\n",
        "    previous_state_dict = torch.load(args.base_model)\n",
        "    model.load_state_dict(previous_state_dict,False,True)\n",
        "    print(\"Previous weight loaded \")\n",
        "  return network\n",
        "\n",
        "class completionargs:\n",
        "  def __init__(self,model, batch_size):\n",
        "    self.model = model\n",
        "    self.batch_size = batch_size\n",
        "    self.nworkers = 2\n",
        "    self.dataset = 'shapenet'\n",
        "    self.pc_augm_scale=0\n",
        "    self.pc_augm_rot=0\n",
        "    self.pc_augm_mirror_prob=0\n",
        "    self.pc_augm_jitter=0\n",
        "    self.inpts=500\n",
        "  def step(self, targets, clouds_data):\n",
        "    clouds_data = torch.from_numpy(clouds_data[1]).cuda()\n",
        "    targets = torch.from_numpy(targets).cuda()\n",
        "    output1, output2, emd1, emd2, expansion_penalty = self.model(clouds_data, targets.contiguous(), 0.005, 10)\n",
        "    dist1, dist2 = chamferDist()(output2.float(),targets.float())\n",
        "    loss = torch.mean(dist2) + torch.mean(dist1)\n",
        "    return loss.item(), dist1, dist2, emd2, output2.detach().cpu().numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1JJSwzjjiK8",
        "outputId": "cd19bc59-dc16-4fc5-873c-e845c702565d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n",
            "/content/repo_folder/completion3d\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = False\n",
        "class opt:\n",
        "  def __init__(self):\n",
        "    self.base_model = '/content/repo_folder/MSN-Point-Cloud-Completion/trained_model/network.pth'\n",
        "    self.epoch_iter_limit_val = 10\n",
        "    self.batchSize = 16\n",
        "    self.epoch_iter_limit = None\n",
        "    self.perc_data = 0.1 if train else 1\n",
        "    self.perc_val_data = 0.1 if train else 0.999\n",
        "    self.workers = 1\n",
        "    self.nepoch = 10\n",
        "    self.model = ''\n",
        "    self.num_points = 8192\n",
        "    self.n_primitives = 16\n",
        "    self.env = \"MSN_TRAIN\"\n",
        "    self.manualSeed = 0\n",
        "    self.run_embedder = True\n",
        "    self.embeddingpath = \"/content/embeddings\"\n",
        "\n",
        "class architect_opts:\n",
        "  def __init__(self, latent_size = 64, gt_layer_sizes = (32,128,512), res_layer_sizes = (256,128,64), use_gt = True, train = train):\n",
        "    self.use_gt = use_gt\n",
        "    self.gt_layer_sizes = (32,128,512)\n",
        "    self.latents = 64\n",
        "    self.res_layer_sizes = (256,128,64)\n",
        "    self.train = train\n",
        "\n",
        "arcargsd = {}\n",
        "\n",
        "argsd = {}\n",
        "arcargsd = {}\n",
        "arcargsd[\"m1\"] = architect_opts(None,None,(512,256,128,64),False,False)\n",
        "#arcargsd[\"m2\"] = architect_opts(None,None,(1024),False,False)\n",
        "#arcargsd[\"m3\"] = architect_opts(None,None,(512),False,False)\n",
        "#arcargsd[\"m4\"] = architect_opts(None,None,(256,64),False,False)\n",
        "#arcargsd[\"m5\"] = architect_opts(None,None,(512),False,False)\n",
        "arcargsd[\"m6\"] = architect_opts(32,(32,256,512),(512,256,128,64))\n",
        "arcargsd[\"m7\"] = architect_opts(64,(1024),(1024))\n",
        "arcargsd[\"m8\"] = architect_opts(64,(512),(512))\n",
        "arcargsd[\"m9\"] = architect_opts(64,(128,512),(256,64))\n",
        "arcargsd[\"m10\"] = architect_opts(64,(512,512),(512))\n",
        "\n",
        "\n",
        "names = arcargsd.keys()\n",
        "\n",
        "for name in names:\n",
        "  argsd[name] = opt()\n",
        "\n",
        "%cd /content/repo_folder/MSN-Point-Cloud-Completion/\n",
        "if train:\n",
        "  for name in names:\n",
        "    if arcargsd[name].train:\n",
        "      save_path = f\"/content/drive/MyDrive/saved/{name}\"\n",
        "      model = make_fuller_model(\"\", argsd[name], arcargsd[name])\n",
        "      trainFull(model,save_path, False, argsd[name])\n",
        "\n",
        "base_model = make_base_model(opt())\n",
        "def print_results_sorted(results):\n",
        "  vs = [(x,results[x]) for x in results]\n",
        "  print([vs[x] for x in np.argsort([x[1] for x in vs])])\n",
        "first = True\n",
        "if False:\n",
        "  %cd /content/repo_folder 3D-FUTURE-AI-Challenge-Baseline\n",
        "  if first:\n",
        "    ! python ./reconstruction/generate.py\n",
        "  def testfunc(x):\n",
        "    ca = completionargs(model,32)\n",
        "    def trainer(data):\n",
        "      ca.step(data[1],data[0])\n",
        "    return eval(x, trainer)\n",
        "else:\n",
        "  if first:\n",
        "    dir = \"/content/repo_folder/completion3d/data\"\n",
        "    link = \"http://download.cs.stanford.edu/downloads/completion3d/dataset2019.zip\"\n",
        "    dataf = \"/content/data.zip\"\n",
        "    ! wget -nc -O $dataf $link\n",
        "    ! rm -r $dir\n",
        "    ! mkdir -p $dir\n",
        "    ! unzip -o $dataf -d $dir\n",
        "  %cd /content/repo_folder/completion3d\n",
        "  testfunc = lambda x : test_on_completion3D(completionargs(x,32),False)\n",
        "\n",
        "results = {}\n",
        "if False:\n",
        "  model = make_base_model(args)\n",
        "  model.cuda()\n",
        "  results[\"base_model\"] = testfunc(model)\n",
        "  print_results_sorted(results)\n",
        "\n",
        "for name in list(names):\n",
        "  save_path = f\"/content/drive/MyDrive/saved/{name}\"\n",
        "  save_file = f'{save_path}/network.pth'\n",
        "  if not os.path.isfile(save_file):\n",
        "    continue\n",
        "  model = make_fuller_model(save_file, argsd[name], arcargsd[name])\n",
        "  model.cuda()\n",
        "  results[name] = testfunc(model)\n",
        "  print_results_sorted(results)\n",
        "  del(model)"
      ],
      "metadata": {
        "id": "XuT-gFr81Djp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efe27aad-ac63-4e19-c4a6-01ea5f21ecd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/repo_folder/MSN-Point-Cloud-Completion\n",
            "Previous weight loaded \n",
            "--2024-01-31 14:08:56--  http://download.cs.stanford.edu/downloads/completion3d/dataset2019.zip\n",
            "Resolving download.cs.stanford.edu (download.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to download.cs.stanford.edu (download.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1585860897 (1.5G) [application/zip]\n",
            "Saving to: ‘/content/data.zip’\n",
            "\n",
            "/content/data.zip    51%[=========>          ] 774.77M  4.91MB/s    eta 2m 26s "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "| model name  | loss * 1000  |   |   |   |\n",
        "|---|---|---|---|---|\n",
        "|  new res non trained | 22  |   |   |   |\n",
        "| global transform new res trained 16 epochs | 16  |   |   |   |\n",
        "| original | 9  |   |   |   |"
      ],
      "metadata": {
        "id": "WLzgzC0kcwwn"
      }
    }
  ]
}