{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OiBsyWYzBbxA",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "outputId": "5f48ce9e-d96c-4fbd-f0ab-be7a768a5062"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<CUDA device 0 'b'Tesla T4''>\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "mkdir: cannot create directory ‘/content/repo_folder’: File exists\n",
      "/content/repo_folder\n",
      "fatal: destination path 'MSN-Point-Cloud-Completion' already exists and is not an empty directory.\n",
      "/content/repo_folder/MSN-Point-Cloud-Completion\n",
      "M\tchanges/dataset.py\n",
      "M\tchanges/train.py\n",
      "Already on 'Pavel'\n",
      "Your branch is up to date with 'origin/Pavel'.\n"
     ]
    }
   ],
   "source": [
    "#! git fetch origin\n",
    "#! git reset --hard origin/master\n",
    "from numba import cuda\n",
    "device = cuda.get_current_device()\n",
    "print(device)\n",
    "device.reset()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "get_base_data = False\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "drivef = \"/content/drive/MyDrive/\"\n",
    "try:\n",
    "  import open3d\n",
    "except:\n",
    "  ! pip install -q open3d\n",
    "  import open3d\n",
    "try:\n",
    "  import open3d\n",
    "except:\n",
    "  ! pip install -q open3d\n",
    "  import open3d\n",
    "try:\n",
    "  import ninja\n",
    "except:\n",
    "  ! pip install -q ninja\n",
    "  import ninja\n",
    "try:\n",
    "  import h5py\n",
    "except:\n",
    "  ! pip install -q h5py\n",
    "  import h5py\n",
    "try:\n",
    "  import transforms3d\n",
    "except:\n",
    "  ! pip install -q transforms3d\n",
    "  import transforms3d\n",
    "\n",
    "!mkdir /content/repo_folder\n",
    "%cd /content/repo_folder\n",
    "!git clone -q https://github.com/iwillnotkillyou/MSN-Point-Cloud-Completion.git\n",
    "%cd ./MSN-Point-Cloud-Completion\n",
    "!git checkout Pavel\n",
    "#!git reset --hard\n",
    "#!git pull"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "dataf = \"/content/repo_folder/MSN-Point-Cloud-Completion/data\"\n",
    "if get_base_data:\n",
    "  if not os.path.isdir(f'{dataf}/val'):\n",
    "    !unzip -n /content/drive/MyDrive/data/val.zip -d $dataf\n",
    "  if not os.path.isdir(f'{dataf}/complete'):\n",
    "    !unzip -n /content/drive/MyDrive/data/complete.zip -d $dataf\n",
    "drivesplitf = \"/content/drive/MyDrive/saved\"\n",
    "valp = f'{drivesplitf}/all.list'\n",
    "valop = f'{drivef}/data/val.list'\n",
    "!cp $valop $valp\n",
    "%cd /content/repo_folder/MSN-Point-Cloud-Completion\n",
    "!mkdir \"/content/repo_folder/MSN-Point-Cloud-Completion/trained_model\"\n",
    "!cp \"/content/drive/MyDrive/data/network.pth\" \"/content/repo_folder/MSN-Point-Cloud-Completion/trained_model/network.pth\""
   ],
   "metadata": {
    "id": "xt0Q5uPzKU8x",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "2e37320d-bcd1-4052-f541-7646c9d2e56d"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/repo_folder/MSN-Point-Cloud-Completion\n",
      "mkdir: cannot create directory ‘/content/repo_folder/MSN-Point-Cloud-Completion/trained_model’: File exists\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#! mkdir /content/saved\n",
    "#! wget -nc -O /content/saved/network.pth https://www.dropbox.com/scl/fi/qx16y8hkfaq0b7nh1k4b2/network.pth?rlkey=w6yjdwy3zpbf25h2qtak6kkq5&dl=0"
   ],
   "metadata": {
    "id": "X5sDPQeoyriv"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%cd /content/repo_folder\n",
    "! git clone -q https://github.com/lynetcha/completion3d.git\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '/content/repo_folder/MSN-Point-Cloud-Completion/')\n",
    "sys.path.insert(1, '/content/repo_folder/MSN-Point-Cloud-Completion/changes')\n",
    "sys.path.insert(1, '/content/repo_folder/MSN-Point-Cloud-Completion/emd')\n",
    "sys.path.insert(1, '/content/repo_folder/completion3d/shared')\n",
    "sys.path.insert(1, '/content/repo_folder/completion3d/shared/datasets')\n",
    "sys.path.insert(1, '/content/repo_folder/completion3d/pytorch')\n",
    "\n",
    "%cd /content/repo_folder/MSN-Point-Cloud-Completion/\n",
    "from full_model import *\n",
    "from transfered_model import *"
   ],
   "metadata": {
    "id": "wf6IuCTvaODK",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ba83a035-d2f4-4c48-cd37-cec91e2859a4"
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/repo_folder\n",
      "fatal: destination path 'completion3d' already exists and is not an empty directory.\n",
      "/content/repo_folder/MSN-Point-Cloud-Completion\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "try:\n",
    "  import trimesh\n",
    "except:\n",
    "  ! pip install -q trimesh\n",
    "  import trimesh\n",
    "%cd /content/repo_folder/MSN-Point-Cloud-Completion/\n",
    "from model import *\n",
    "from train import *\n",
    "from my_chamfer_interface import chamferDist\n",
    "class completionargs:\n",
    "  def __init__(self,model, batch_size, name, fol):\n",
    "    self.model = model\n",
    "    self.name = name\n",
    "    self.fol = fol\n",
    "    self.batch_size = batch_size\n",
    "    self.nworkers = 2\n",
    "    self.dataset = 'shapenet'\n",
    "    self.pc_augm_scale=0\n",
    "    self.pc_augm_rot=0\n",
    "    self.pc_augm_mirror_prob=0\n",
    "    self.pc_augm_jitter=0\n",
    "    self.inpts=500\n",
    "  def step(self, targets, clouds_data, i):\n",
    "    clouds_data = torch.from_numpy(clouds_data[1]).cuda()\n",
    "    targets = torch.from_numpy(targets).cuda()\n",
    "    output1, output2, emd1, emd2, expansion_penalty = self.model(clouds_data, targets.contiguous(), 0.005, 10)\n",
    "    dist1, dist2 = chamferDist()(output2.float(),targets.float())\n",
    "    loss = torch.mean(dist2) + torch.mean(dist1)\n",
    "    if self.fol is not None:\n",
    "      printf(clouds_data,output2,targets,i,f\"{self.name}{int(torch.mean(emd1).item()*10000)}-{int(torch.mean(emd2).item()*10000)}-{int(torch.mean(loss).item()*10000)}\",self.fol)\n",
    "    return loss.item(), dist1, dist2, emd2, output2.detach().cpu().numpy()"
   ],
   "metadata": {
    "id": "E1JJSwzjjiK8",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4a629171-5782-4d18-91e2-ec3200a96b7c"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "/content/repo_folder/MSN-Point-Cloud-Completion\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%cd /content/repo_folder/MSN-Point-Cloud-Completion/\n",
    "class PointNetfeatFreeze(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(3, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "\n",
    "        self.bn1 = torch.nn.BatchNorm1d(64)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(128)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(1024)\n",
    "\n",
    "    def freeze(self):\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        x, _ = torch.max(x, 2)\n",
    "        x = x.view(-1, 1024)\n",
    "        return x\n",
    "\n",
    "\n",
    "import torch\n",
    "from changes.train import *\n",
    "from test_on_completion3d import test_on_completion3D\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def make_fuller_model(name, args, architect_args):\n",
    "  def additionalencoderf():\n",
    "    if architect_args.additional_sizes is None:\n",
    "      return AdditionalEncoderIndentity()\n",
    "    return AdditionalEncoder(architect_args.additional_sizes,architect_args.additional_latents)\n",
    "  def pointnetfeatf():\n",
    "    if architect_args.modif_sizes is None:\n",
    "      return PointNetfeatFreeze()\n",
    "    if architect_args.modif_partial:\n",
    "      return PointNetfeatReturn2TPartial(architect_args.modif_sizes)\n",
    "    return PointNetfeatReturn2(architect_args.modif_sizes,architect_args.modif_latents)\n",
    "  def additionaldecoderf():\n",
    "    return GlobalTransformDepthSep(3, architect_args.additional_dec_sizes, 3, 1024)\n",
    "  additionaldecoderf = None if architect_args.additional_dec_sizes is None else additionaldecoderf\n",
    "  model = TransformMSN(additionalencoderf, pointnetfeatf, additionaldecoderf, args.num_points, architect_args.train_encoder)\n",
    "\n",
    "  network = FullModel(model)\n",
    "  model.cuda()\n",
    "  #network = torch.nn.DataParallel(network)\n",
    "  #model.apply(weights_init) #initialization of the weight\n",
    "  if name != '':\n",
    "      previous_state_dict = torch.load(name)\n",
    "      model.load_state_dict(previous_state_dict,False,True)\n",
    "      print(\"Previous weight loaded \")\n",
    "  elif args.base_model != '':\n",
    "      previous_state_dict = torch.load(args.base_model)\n",
    "      model.load_state_dict(previous_state_dict,False,True)\n",
    "      print(\"Base weight loaded \")\n",
    "  model.freeze()\n",
    "  network.cuda()\n",
    "  return network\n",
    "\n",
    "def make_base_model(args):\n",
    "  model = MSN()\n",
    "  network = FullModel(model)\n",
    "  if args.base_model != '':\n",
    "    previous_state_dict = torch.load(args.base_model)\n",
    "    model.load_state_dict(previous_state_dict,False,True)\n",
    "    print(\"Base weight loaded \")\n",
    "  return network\n",
    "\n",
    "train = True\n",
    "class opt:\n",
    "  def __init__(self):\n",
    "    self.base_model = '/content/repo_folder/MSN-Point-Cloud-Completion/trained_model/network.pth'\n",
    "    self.epoch_iter_limit_val = 10\n",
    "    self.batchSize = 12\n",
    "    self.epoch_iter_limit = None\n",
    "    self.perc_data = 0.95\n",
    "    self.perc_val_data = 0.1\n",
    "    self.workers = 1\n",
    "    self.nepoch = 10\n",
    "    self.model = ''\n",
    "    self.num_points = 8192\n",
    "    self.n_primitives = 16\n",
    "    self.env = \"MSN_TRAIN\"\n",
    "    self.manualSeed = 0\n",
    "    self.run_embedder = True\n",
    "    self.embeddingpath = \"/content/embeddings\"\n",
    "    self.usefirstorder = True\n",
    "\n",
    "class architect_opts:\n",
    "  def __init__(self, additional_enc = None, modif = None, additional_dec = None, shared_latents = None, modif_partial = True, train_encoder = False, train = train):\n",
    "    dontuseshared = shared_latents is None\n",
    "    def getval(tup):\n",
    "      return tup[1] if dontuseshared and tup is not None else tup, tup[0] if dontuseshared and tup is not None else shared_latents\n",
    "\n",
    "    self.additional_sizes, self.additional_latents = getval(additional_enc)\n",
    "    self.modif_sizes, self.modif_latents = getval(modif)\n",
    "    self.additional_dec_sizes, self.additional_dec_latents = getval(additional_dec)\n",
    "    self.train = train\n",
    "    self.modif_partial = modif_partial\n",
    "    self.train_encoder = train_encoder\n",
    "\n",
    "arcargsd = {}\n",
    "\n",
    "argsd = {}\n",
    "arcargsd = {}\n",
    "arcargsd[\"m2\"] = architect_opts((32,(256,256)),None,None,train = False,train_encoder=True)\n",
    "arcargsd[\"m3\"] = architect_opts((32,(128,128)),(32,(128,)),(32,(128,)),train = False)\n",
    "arcargsd[\"m4\"] = architect_opts((32,(256,256)),None,None,train = False,train_encoder=True)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "names = arcargsd.keys()\n",
    "\n",
    "for name in names:\n",
    "  argsd[name] = opt()\n",
    "argsd[\"m4\"].model = \"/content/drive/MyDrive/saved/m2/network.pth\"\n",
    "def makeso(args):\n",
    "  args.usefirstorder = False\n",
    "  args.batchSize = 64\n",
    "drivesplitf = \"/content/drive/MyDrive/saved\"\n",
    "#makeso(argsd[\"m2\"])\n",
    "#makeso(argsd[\"m4\"])\n",
    "#makeso(argsd[\"m6\"])\n",
    "resplit = True\n",
    "trainon3df = True\n",
    "if not trainon3df:\n",
    "  trainp = f'{drivesplitf}/train.list'\n",
    "  valp = f'{drivesplitf}/val.list'\n",
    "  testp = f'{drivesplitf}/test.list'\n",
    "  if resplit:\n",
    "      make_data_splits(opt(),f'{drivesplitf}/all.list',\n",
    "                      trainp,\n",
    "                      valp,\n",
    "                      testp)\n",
    "else:\n",
    "  !unzip -n /content/drive/MyDrive/data/3Dfuture.zip -d \"/content/repo_folder/MSN-Point-Cloud-Completion/data\"\n",
    "  trainp = f'{drivesplitf}/train3dfuture.list'\n",
    "  valp = f'{drivesplitf}/val3dfuture.list'\n",
    "  testp = f'{drivesplitf}/test3dfuture.list'\n",
    "  if resplit:\n",
    "      make_data_splits(opt(),f'/content/drive/MyDrive/data/list3dfuture',\n",
    "                      trainp,\n",
    "                      valp,\n",
    "                      testp)\n",
    "def plotrainval(save_path):\n",
    "  p = f\"{save_path}/curves.npy\"\n",
    "  if not os.path.isfile(p):\n",
    "    return\n",
    "  curves = np.load(p)[1:]\n",
    "  plt.plot(curves[0,:],label = \"train emd\")\n",
    "  plt.plot(curves[1,:],label = \"val emd\")\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "  plt.plot(curves[2,:],label = \"train cd\")\n",
    "  plt.plot(curves[3,:],label = \"val cd\")\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "if train:\n",
    "  for name in names:\n",
    "    if arcargsd[name].train:\n",
    "      save_path = f\"/content/drive/MyDrive/saved/{name}\"\n",
    "      model = make_fuller_model(argsd[name].model, argsd[name], arcargsd[name])\n",
    "      cs = 0\n",
    "      for c in model.model.children():\n",
    "        csc = 0\n",
    "        for param in c.parameters():\n",
    "          if param.requires_grad:\n",
    "            csc += param.nelement()\n",
    "        cs += csc\n",
    "        print(type(c), csc, cs)\n",
    "      trainFull(model,save_path, argsd[name], 50, 1e-3, trainp=trainp,\n",
    "              valp=valp,obj = True)\n",
    "      plotrainval(save_path)\n",
    "\n",
    "\n",
    "base_model = make_base_model(opt())\n",
    "def print_results_sorted(results):\n",
    "  vs = [(x,results[x]) for x in results]\n",
    "  print([vs[x] for x in np.argsort([x[1] for x in vs])])\n",
    "\n",
    "\n",
    "resultsavef = f'{drivesplitf}/output'\n",
    "if False:\n",
    "  dir = \"/content/repo_folder/completion3d/data\"\n",
    "  link = \"http://download.cs.stanford.edu/downloads/completion3d/dataset2019.zip\"\n",
    "  dataf = \"/content/data.zip\"\n",
    "  ! wget -nc -O $dataf $link\n",
    "  if not os.path.isdir(dir):\n",
    "    ! mkdir -p $dir\n",
    "    ! unzip -qq -o $dataf -d $dir\n",
    "  %cd /content/repo_folder/completion3d/\n",
    "  def testfunc(x, name):\n",
    "    return test_on_completion3D(completionargs(x,4,name,None if False else resultsavef),False)\n",
    "elif False:\n",
    "  dataset_test = ShapeNet(testp, npoints=opt().num_points)\n",
    "  dataset_test, _ = torch.utils.data.random_split(dataset_test,[0.1,0.9])\n",
    "  dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size= 64,shuffle=False, num_workers=opt().workers, drop_last=True)\n",
    "  def testfunc(x, name):\n",
    "    return np.mean(test(x,dataloader_test,name,64,resultsavef+\"based\")[0])\n",
    "else:\n",
    "  !unzip -n /content/drive/MyDrive/data/3Dfuture.zip -d \"/content/repo_folder/MSN-Point-Cloud-Completion/data\"\n",
    "  dataset_test = ShapeNetOBJ(testp)\n",
    "  dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size= 64,shuffle=False, num_workers=opt().workers, drop_last=True)\n",
    "  def testfunc(x, name):\n",
    "    return np.mean(test(x,dataloader_test,name,64,resultsavef+\"3dfuture\")[0])\n",
    "print(len(dataset_test))\n",
    "results = {}\n",
    "if True:\n",
    "  model = make_base_model(opt())\n",
    "  model.cuda()\n",
    "  results[\"base_model\"] = testfunc(model,\"base_model\")\n",
    "  print_results_sorted(results)\n",
    "  del(model)\n",
    "\n",
    "for name in list(names):\n",
    "  print(name)\n",
    "  save_path = f\"/content/drive/MyDrive/saved/{name}\"\n",
    "  save_file = f'{save_path}/network.pth'\n",
    "  print(os.path.isfile(save_file))\n",
    "  if not os.path.isfile(save_file):\n",
    "    continue\n",
    "  #plotrainval(save_path)\n",
    "  model = make_fuller_model(save_file, argsd[name], arcargsd[name])\n",
    "  model.cuda()\n",
    "  results[name] = testfunc(model,name)\n",
    "  print_results_sorted(results)\n",
    "  del(model)"
   ],
   "metadata": {
    "id": "XuT-gFr81Djp",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "eed3ccd7-ae77-4de7-987c-6d806cedd3a9"
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/repo_folder/MSN-Point-Cloud-Completion\n",
      "Archive:  /content/drive/MyDrive/data/3Dfuture.zip\n",
      "Base weight loaded \n",
      "Archive:  /content/drive/MyDrive/data/3Dfuture.zip\n",
      "100\n",
      "Base weight loaded \n",
      "0.17193955183029175 0.2027285099029541 0.0029690396040678024\n",
      "test emd1: 0.213074 emd2: 0.171940 expansion_penalty: 0.002969 cd : 0.202729\n",
      "[('base_model', 0.2027285099029541)]\n",
      "m2\n",
      "True\n",
      "Previous weight loaded \n",
      "0.16358625888824463 0.16968634724617004 0.0028686411678791046\n",
      "test emd1: 0.205849 emd2: 0.163586 expansion_penalty: 0.002869 cd : 0.169686\n",
      "[('m2', 0.16968634724617004), ('base_model', 0.2027285099029541)]\n",
      "m3\n",
      "False\n",
      "m4\n",
      "True\n",
      "Previous weight loaded \n",
      "0.1588815152645111 0.19322019815444946 0.0034917977172881365\n",
      "test emd1: 0.225787 emd2: 0.158882 expansion_penalty: 0.003492 cd : 0.193220\n",
      "[('m2', 0.16968634724617004), ('m4', 0.19322019815444946), ('base_model', 0.2027285099029541)]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "```[('base_model', 0.0017337317415513098),\n",
    "('m7', 0.0020423539844341577),\n",
    "('m1', 0.003960765758529305),\n",
    "('m10', 0.008972912528552115),\n",
    "('m8', 0.011971391048282385)]\n",
    "[('m16', 0.0020216004084795715), ('m15', 0.006628909669816494)] 'm17', 0.0023083634383510797\n",
    "[('m1', 0.0015856193285435439)]\n",
    "\n",
    "[('m2', 0.001651345631107688), ('m1', 0.0017085947841405868), ('base_model', 0.0017209897947032004)]\n",
    "\n",
    "test emd1: 0.021308 emd2: 0.019169 expansion_penalty: 0.002754 cd : 0.000565\n",
    "test emd1: 0.027037 emd2: 0.023807 expansion_penalty: 0.002644 cd : 0.000707\n",
    "```"
   ],
   "metadata": {
    "id": "WLzgzC0kcwwn"
   }
  }
 ]
}
